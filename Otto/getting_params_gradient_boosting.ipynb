{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(15000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 15 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 5\n",
    "%autosave 15\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Data/train.csv')\n",
    "train_data = train_data.drop(\"id\", axis = 1)\n",
    "def convert_target(x):\n",
    "    return int(x[\"target\"].split('_')[1])\n",
    "train_data[\"target\"] = train_data.apply(convert_target, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import datetime, time\n",
    "def test_method(method, a_train, a_test, b_train, b_test):\n",
    "    print method.__class__\n",
    "    method.fit(a_train, b_train)\n",
    "    print log_loss(b_train, method.predict_proba(a_train))\n",
    "\n",
    "def test_methods(methods, a_train, a_test, b_train, b_test):\n",
    "    for method in methods:\n",
    "        test_method(method, a_train, a_test, b_train, b_test)\n",
    "\n",
    "def test_models(data):\n",
    "    target = data.target\n",
    "    train = data.drop('target', axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size = 0.2, random_state = 42)\n",
    "    methods = [RandomForestClassifier(n_estimators = 100)]\n",
    "    test_methods(methods, X_train, X_test, y_train, y_test)\n",
    "\n",
    "def get_best_params(method, params, data):\n",
    "    target = data.target\n",
    "    train = data.drop('target', axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size = 0.2, random_state = 42)\n",
    "    errors_train, errors_test = aggregate_train_test_errors(method, params, X_train, y_train, X_test, y_test, [log_loss], print_flag=True)\n",
    "    plot_train_test_errors(method, params, errors_train, errors_test)\n",
    "    \n",
    "def print_score(model, metric, X_train, y_train, X_test, y_test):\n",
    "        print(\"Model: %s Metric: %s On test: %f\" % (model.__class__.__name__, metric.__name__, metric(y_test, model.predict_proba(X_test))))\n",
    "        \n",
    "def print_scores(model, metrics, X_train, y_train, X_test, y_test, parameter = None):\n",
    "    for metric in metrics:\n",
    "        if parameter != None:\n",
    "            print(\"%s %s\" % (parameter[0], parameter[1]))\n",
    "            print_score(model, metric, X_train, y_train, X_test, y_test)\n",
    "        else:\n",
    "            print_score(model, metric, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "def aggregate_train_test_errors(model, params, X_train, y_train, X_test, y_test, metrics = [], print_flag = False):\n",
    "    errors_train = {key: {'params': params[key], 'values': []} for key in params.keys()}\n",
    "    errors_test = {key: {'params': params[key], 'values': []}  for key in params.keys()}\n",
    "    base_parameters = model.get_params()\n",
    "    start_time = time.time()\n",
    "    prev_time = start_time\n",
    "    for key, values in params.iteritems():\n",
    "        if isinstance(values, list):\n",
    "            for value in values:\n",
    "                model.set_params(**{key: value})\n",
    "                model.fit(X_train, y_train)\n",
    "                cur_time = time.time()\n",
    "                from_start = datetime.datetime.fromtimestamp(cur_time - start_time + time.timezone).strftime('%H:%M:%S')\n",
    "                from_last = datetime.datetime.fromtimestamp(cur_time - prev_time + time.timezone).strftime('%H:%M:%S')\n",
    "                print from_start + \" (\" + from_last + \")\"\n",
    "                prev_time = cur_time\n",
    "                errors_train[key]['values'].append(model.score(X_train, y_train))\n",
    "                errors_test[key]['values'].append(model.score(X_test, y_test))\n",
    "                if print_flag == True and metrics:\n",
    "                    print_scores(model, metrics, X_train, y_train, X_test, y_test, (key, value))\n",
    "            model.set_params(**base_parameters)\n",
    "        else:\n",
    "            raise Exception(\"Take only list of parameters!\")   \n",
    "    return errors_train, errors_test\n",
    "\n",
    "def plot_train_test_errors(model, model_params, errors_train, errors_test, save = None):\n",
    "    fig, axes = plt.subplots(ncols=len(model_params))\n",
    "    fig.set_size_inches((15,9))\n",
    "    for ind, param in enumerate(model_params.keys()):\n",
    "        if isinstance(errors_train[param]['params'][0], str):\n",
    "            axes[ind].plot(range(len(errors_train[param]['params'])), errors_train[param]['values'], label = 'on train')\n",
    "            axes[ind].plot(range(len(errors_train[param]['params'])), errors_test[param]['values'], label = 'on test')\n",
    "            axes[ind].xaxis.set_ticks(range(len(errors_train[param]['params'])), errors_train[param]['params'])\n",
    "        else:            \n",
    "            axes[ind].plot(errors_train[param]['params'], errors_train[param]['values'], label = 'on train')\n",
    "            axes[ind].plot(errors_train[param]['params'], errors_test[param]['values'], label = 'on test')\n",
    "            axes[ind].xaxis.set_ticks(range(len(errors_train[param]['params'])), errors_train[param]['params'])\n",
    "        axes[ind].set_title(str(param))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_best_params = {\"n_estimators\": 600, \n",
    "                  \"max_depth\": 9,\n",
    "                  \"max_features\" : 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       85596.7717          106.18m\n",
      "         2       73668.7873          106.28m\n",
      "         3       65173.3394          106.40m\n",
      "         4       58595.1975          106.41m\n",
      "         5       53128.5161          106.66m\n",
      "         6       48680.5411          106.49m\n",
      "         7       44992.3642          106.76m\n",
      "         8       41834.8191          106.37m\n",
      "         9       39104.2283          106.27m\n",
      "        10       36728.2096          106.53m\n",
      "        20       23466.2341          106.52m\n",
      "        30       17478.9074          107.77m\n",
      "        40       13983.9349          106.08m\n",
      "        50       11574.0767          104.48m\n",
      "        60        9824.2811          102.81m\n",
      "        70        8408.7248          100.95m\n",
      "        80        7358.1647           98.61m\n",
      "        90        6514.8144           96.32m\n",
      "       100        5749.9801           94.32m\n",
      "       200        2052.7256           74.08m\n",
      "       300         820.0813           55.51m\n",
      "       400         312.3349           34.21m\n",
      "       500         123.1904           15.40m\n",
      "       600          52.1025            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=9, max_features=30, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2, n_estimators=600,\n",
       "              random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=600, max_depth=9, max_features=30, verbose=1)\n",
    "target = train_data.target\n",
    "train = train_data.drop('target', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size = 0.2, random_state = 42)\n",
    "clf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
