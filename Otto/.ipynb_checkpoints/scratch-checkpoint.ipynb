{
 "metadata": {
  "name": "",
  "signature": "sha256:c36e02264d3c766acba6db071c0d9797ea6df1b8e1babad99469813461be9474"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 5\n",
      "%autosave 15\n",
      "\n",
      "import pandas as pd\n",
      "import scipy as sp\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import math\n",
      "\n",
      "import sklearn\n",
      "from sklearn import datasets\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
      "from sklearn.svm import SVC, SVR\n",
      "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
      "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
      "from sklearn.grid_search import GridSearchCV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      },
      {
       "javascript": [
        "IPython.notebook.set_autosave_interval(15000)"
       ],
       "metadata": {},
       "output_type": "display_data"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Autosaving every 15 seconds\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data = pd.read_csv('Data/train.csv')\n",
      "train_data.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>feat_1</th>\n",
        "      <th>feat_2</th>\n",
        "      <th>feat_3</th>\n",
        "      <th>feat_4</th>\n",
        "      <th>feat_5</th>\n",
        "      <th>feat_6</th>\n",
        "      <th>feat_7</th>\n",
        "      <th>feat_8</th>\n",
        "      <th>feat_9</th>\n",
        "      <th>...</th>\n",
        "      <th>feat_84</th>\n",
        "      <th>feat_85</th>\n",
        "      <th>feat_86</th>\n",
        "      <th>feat_87</th>\n",
        "      <th>feat_88</th>\n",
        "      <th>feat_89</th>\n",
        "      <th>feat_90</th>\n",
        "      <th>feat_91</th>\n",
        "      <th>feat_92</th>\n",
        "      <th>feat_93</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.00000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td>...</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "      <td> 61878.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td> 30939.500000</td>\n",
        "      <td>     0.38668</td>\n",
        "      <td>     0.263066</td>\n",
        "      <td>     0.901467</td>\n",
        "      <td>     0.779081</td>\n",
        "      <td>     0.071043</td>\n",
        "      <td>     0.025696</td>\n",
        "      <td>     0.193704</td>\n",
        "      <td>     0.662433</td>\n",
        "      <td>     1.011296</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.070752</td>\n",
        "      <td>     0.532306</td>\n",
        "      <td>     1.128576</td>\n",
        "      <td>     0.393549</td>\n",
        "      <td>     0.874915</td>\n",
        "      <td>     0.457772</td>\n",
        "      <td>     0.812421</td>\n",
        "      <td>     0.264941</td>\n",
        "      <td>     0.380119</td>\n",
        "      <td>     0.126135</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td> 17862.784315</td>\n",
        "      <td>     1.52533</td>\n",
        "      <td>     1.252073</td>\n",
        "      <td>     2.934818</td>\n",
        "      <td>     2.788005</td>\n",
        "      <td>     0.438902</td>\n",
        "      <td>     0.215333</td>\n",
        "      <td>     1.030102</td>\n",
        "      <td>     2.255770</td>\n",
        "      <td>     3.474822</td>\n",
        "      <td>...</td>\n",
        "      <td>     1.151460</td>\n",
        "      <td>     1.900438</td>\n",
        "      <td>     2.681554</td>\n",
        "      <td>     1.575455</td>\n",
        "      <td>     2.115466</td>\n",
        "      <td>     1.527385</td>\n",
        "      <td>     4.597804</td>\n",
        "      <td>     2.045646</td>\n",
        "      <td>     0.982385</td>\n",
        "      <td>     1.201720</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     0.00000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td> 15470.250000</td>\n",
        "      <td>     0.00000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td> 30939.500000</td>\n",
        "      <td>     0.00000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 46408.750000</td>\n",
        "      <td>     0.00000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     1.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "      <td>     0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 61878.000000</td>\n",
        "      <td>    61.00000</td>\n",
        "      <td>    51.000000</td>\n",
        "      <td>    64.000000</td>\n",
        "      <td>    70.000000</td>\n",
        "      <td>    19.000000</td>\n",
        "      <td>    10.000000</td>\n",
        "      <td>    38.000000</td>\n",
        "      <td>    76.000000</td>\n",
        "      <td>    43.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>    76.000000</td>\n",
        "      <td>    55.000000</td>\n",
        "      <td>    65.000000</td>\n",
        "      <td>    67.000000</td>\n",
        "      <td>    30.000000</td>\n",
        "      <td>    61.000000</td>\n",
        "      <td>   130.000000</td>\n",
        "      <td>    52.000000</td>\n",
        "      <td>    19.000000</td>\n",
        "      <td>    87.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 94 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
        "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
        "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
        "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
        "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
        "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
        "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
        "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
        "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
        "\n",
        "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
        "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
        "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
        "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
        "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
        "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
        "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
        "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
        "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
        "\n",
        "           ...            feat_84       feat_85       feat_86       feat_87  \\\n",
        "count      ...       61878.000000  61878.000000  61878.000000  61878.000000   \n",
        "mean       ...           0.070752      0.532306      1.128576      0.393549   \n",
        "std        ...           1.151460      1.900438      2.681554      1.575455   \n",
        "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
        "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
        "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
        "75%        ...           0.000000      0.000000      1.000000      0.000000   \n",
        "max        ...          76.000000     55.000000     65.000000     67.000000   \n",
        "\n",
        "            feat_88       feat_89       feat_90       feat_91       feat_92  \\\n",
        "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
        "mean       0.874915      0.457772      0.812421      0.264941      0.380119   \n",
        "std        2.115466      1.527385      4.597804      2.045646      0.982385   \n",
        "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
        "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
        "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
        "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
        "max       30.000000     61.000000    130.000000     52.000000     19.000000   \n",
        "\n",
        "            feat_93  \n",
        "count  61878.000000  \n",
        "mean       0.126135  \n",
        "std        1.201720  \n",
        "min        0.000000  \n",
        "25%        0.000000  \n",
        "50%        0.000000  \n",
        "75%        0.000000  \n",
        "max       87.000000  \n",
        "\n",
        "[8 rows x 94 columns]"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = RandomForestClassifier()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data = train_data.drop(\"id\", axis = 1)\n",
      "def convert_target(x):\n",
      "    return int(x[\"target\"].split('_')[1])\n",
      "train_data[\"target\"] = train_data.apply(convert_target, axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import log_loss, accuracy_score\n",
      "def test_method(method, a_train, a_test, b_train, b_test):\n",
      "    print method.__class__\n",
      "    method.fit(a_train, b_train)\n",
      "    print log_loss(b_train, method.predict_proba(a_train))\n",
      "    #print method.score(a_train, b_train)\n",
      "\n",
      "def test_methods(methods, a_train, a_test, b_train, b_test):\n",
      "    for method in methods:\n",
      "        test_method(method, a_train, a_test, b_train, b_test)\n",
      "\n",
      "def test_models(data):\n",
      "    target = data.target\n",
      "    train = data.drop('target', axis = 1)\n",
      "    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size = 0.2, random_state = 42)\n",
      "    \n",
      "    rf_best_params = {\"n_estimators\": [450,500], \n",
      "                  \"max_depth\": [10,15,20], \n",
      "                  \"min_samples_split\": [6,13], \n",
      "                  \"min_samples_leaf\": [1,3],\n",
      "                  \"max_features\": [20,30,40]}\n",
      "    methods = [RandomForestClassifier(n_estimators = 100)]\n",
      "    #test_methods(methods, a_train, a_test, b_train, b_test)\n",
      "    errors_train, errors_test = aggregate_train_test_errors(RandomForestClassifier(), rf_params, X_train, y_train, X_test, y_test, [log_loss], print_flag=True)\n",
      "    plot_train_test_errors(RandomForestClassifier(), rf_params, errors_train, errors_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_models(train_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
        "0.658018071206"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
        "0.160724035588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = train_data['target'].values\n",
      "train = train_data.drop(['target'], axis = 1)\n",
      "clf.fit(train, target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = pd.read_csv('Data/test.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...], dtype='int64')"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = test.drop(\"id\", axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "labels ['id'] not contained in axis",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-65-4012da1b081d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/home/pinguinson/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, level, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   1462\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1465\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pinguinson/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels)\u001b[0m\n\u001b[0;32m   1829\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1830\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1831\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels %s not contained in axis'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1832\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: labels ['id'] not contained in axis"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predicted = clf.predict_proba(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub = pd.DataFrame(predicted, columns = ['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub[\"id\"] = list(range(1,len(sub.index) + 1))\n",
      "sub.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Class_1</th>\n",
        "      <th>Class_2</th>\n",
        "      <th>Class_3</th>\n",
        "      <th>Class_4</th>\n",
        "      <th>Class_5</th>\n",
        "      <th>Class_6</th>\n",
        "      <th>Class_7</th>\n",
        "      <th>Class_8</th>\n",
        "      <th>Class_9</th>\n",
        "      <th>id</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.3</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0.5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.4</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.4</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.6</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.2</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0.7</td>\n",
        "      <td> 5</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "   Class_1  Class_2  Class_3  Class_4  Class_5  Class_6  Class_7  Class_8  \\\n",
        "0      0.0      0.3      0.1      0.5        0      0.1        0      0.0   \n",
        "1      0.0      0.1      0.1      0.0        0      0.4        0      0.4   \n",
        "2      0.0      0.0      0.0      0.0        0      1.0        0      0.0   \n",
        "3      0.0      0.6      0.2      0.0        0      0.0        0      0.0   \n",
        "4      0.2      0.0      0.0      0.0        0      0.0        0      0.1   \n",
        "\n",
        "   Class_9  id  \n",
        "0      0.0   1  \n",
        "1      0.0   2  \n",
        "2      0.0   3  \n",
        "3      0.2   4  \n",
        "4      0.7   5  "
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cols = sub.columns.tolist()\n",
      "cols = cols[-1:] + cols[:-1]\n",
      "sub = sub[cols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>Class_1</th>\n",
        "      <th>Class_2</th>\n",
        "      <th>Class_3</th>\n",
        "      <th>Class_4</th>\n",
        "      <th>Class_5</th>\n",
        "      <th>Class_6</th>\n",
        "      <th>Class_7</th>\n",
        "      <th>Class_8</th>\n",
        "      <th>Class_9</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.3</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0.5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.4</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.4</td>\n",
        "      <td> 0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.6</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0.7</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "   id  Class_1  Class_2  Class_3  Class_4  Class_5  Class_6  Class_7  Class_8  \\\n",
        "0   1      0.0      0.3      0.1      0.5        0      0.1        0      0.0   \n",
        "1   2      0.0      0.1      0.1      0.0        0      0.4        0      0.4   \n",
        "2   3      0.0      0.0      0.0      0.0        0      1.0        0      0.0   \n",
        "3   4      0.0      0.6      0.2      0.0        0      0.0        0      0.0   \n",
        "4   5      0.2      0.0      0.0      0.0        0      0.0        0      0.1   \n",
        "\n",
        "   Class_9  \n",
        "0      0.0  \n",
        "1      0.0  \n",
        "2      0.0  \n",
        "3      0.2  \n",
        "4      0.7  "
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sub.to_csv('Data/submission.csv', index = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_models(train_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
        "0.863422722149"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf_params = {\"n_estimators\": [10,50,100,250,400,550,700], \n",
      "             \"criterion\": [\"gini\", \"entropy\"], \n",
      "             \"max_depth\": range(1, 26, 2), \n",
      "             \"min_samples_split\": range(1, 26, 2), \n",
      "             \"min_samples_leaf\": range(1, 26, 2), \n",
      "             \"max_features\": range(10, 100, 10)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_score(model, metric, X_train, y_train, X_test, y_test):\n",
      "    if metric.__name__ in [\"accuracy_score\"]:\n",
      "        #print(\"Model: %s Metric: %s On train: %f\" % (model.__class__.__name__, metric.__name__, metric(y_train, model.predict(X_train))))\n",
      "        print(\"Model: %s Metric: %s On test: %f\" % (model.__class__.__name__, metric.__name__, metric(y_test, model.predict(X_test))))\n",
      "    else:\n",
      "        #print(\"Model: %s Metric: %s On train: %f\" % (model.__class__.__name__, metric.__name__, metric(y_train, model.predict_proba(X_train))))\n",
      "        print(\"Model: %s Metric: %s On test: %f\" % (model.__class__.__name__, metric.__name__, metric(y_test, model.predict_proba(X_test))))\n",
      "        \n",
      "def print_scores(model, metrics, X_train, y_train, X_test, y_test, parameter = None):\n",
      "    for metric in metrics:\n",
      "        if parameter != None:\n",
      "            print(\"%s %s\" % (parameter[0], parameter[1]))\n",
      "            print_score(model, metric, X_train, y_train, X_test, y_test)\n",
      "        else:\n",
      "            print_score(model, metric, X_train, y_train, X_test, y_test)\n",
      "    \n",
      "def aggregate_train_test_errors(model, params, X_train, y_train, X_test, y_test, metrics = [], print_flag = False):\n",
      "    errors_train = {key: {'params': params[key], 'values': []} for key in params.keys()}\n",
      "    errors_test = {key: {'params': params[key], 'values': []}  for key in params.keys()}\n",
      "    base_parameters = model.get_params()\n",
      "    for key, values in params.iteritems():\n",
      "        if isinstance(values, list):\n",
      "            for value in values:\n",
      "                model.set_params(**{key: value})\n",
      "                model.fit(X_train, y_train)\n",
      "                errors_train[key]['values'].append(model.score(X_train, y_train))\n",
      "                errors_test[key]['values'].append(model.score(X_test, y_test))\n",
      "                if print_flag == True and metrics:\n",
      "                    print_scores(model, metrics, X_train, y_train, X_test, y_test, (key, value))\n",
      "            model.set_params(**base_parameters)\n",
      "        else:\n",
      "            raise Exception(\"Take only list of parameters!\")   \n",
      "    return errors_train, errors_test\n",
      "\n",
      "def plot_train_test_errors(model, model_params, errors_train, errors_test, save = None):\n",
      "    fig, axes = plt.subplots(ncols=len(model_params))\n",
      "    fig.set_size_inches((15,9))\n",
      "    for ind, param in enumerate(model_params.keys()):\n",
      "        if isinstance(errors_train[param]['params'][0], str):\n",
      "            axes[ind].plot(range(len(errors_train[param]['params'])), errors_train[param]['values'], label = 'on train')\n",
      "            axes[ind].plot(range(len(errors_train[param]['params'])), errors_test[param]['values'], label = 'on test')\n",
      "            axes[ind].xaxis.set_ticks(range(len(errors_train[param]['params'])), errors_train[param]['params'])\n",
      "        else:            \n",
      "            axes[ind].plot(errors_train[param]['params'], errors_train[param]['values'], label = 'on train')\n",
      "            axes[ind].plot(errors_train[param]['params'], errors_test[param]['values'], label = 'on test')\n",
      "            axes[ind].xaxis.set_ticks(range(len(errors_train[param]['params'])), errors_train[param]['params'])\n",
      "        axes[ind].set_title(str(param))\n",
      "    plt.legend()\n",
      "    plt.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_models(train_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "min_samples_leaf 1\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 1.496499"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.745206"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.710818"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.712698"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.721043"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.722068"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.735181"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.736141"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.746468"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.756331"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 21"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.750878"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 23"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.769476"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "min_samples_leaf 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.769370"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "n_estimators 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 1.488833"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "n_estimators 50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model: RandomForestClassifier Metric: log_loss On test: 0.668291"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-133-efe916af62d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-130-7dd28db3747d>\u001b[0m in \u001b[0;36mtest_models\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmethods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#test_methods(methods, a_train, a_test, b_train, b_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0merrors_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggregate_train_test_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_flag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mplot_train_test_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-132-34b4bc907680>\u001b[0m in \u001b[0;36maggregate_train_test_errors\u001b[1;34m(model, params, X_train, y_train, X_test, y_test, metrics, print_flag)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0merrors_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0merrors_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pinguinson/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                 verbose=self.verbose)\n\u001b[1;32m--> 279\u001b[1;33m             for i in range(n_jobs))\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pinguinson/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pinguinson/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \"\"\"\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pinguinson/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pinguinson/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(trees, forest, X, y, sample_weight, verbose)\u001b[0m\n\u001b[0;32m     87\u001b[0m             tree.fit(X, y,\n\u001b[0;32m     88\u001b[0m                      \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                      check_input=False)\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_counts\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pinguinson/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_mask, X_argsorted, check_input, sample_weight)\u001b[0m\n\u001b[0;32m    265\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 133
    }
   ],
   "metadata": {}
  }
 ]
}