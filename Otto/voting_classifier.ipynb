{
 "metadata": {
  "name": "",
  "signature": "sha256:25532a035ed3c67fdd290568730d5a6e8da72edaac5976e2c8ad1e707e804806"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 5\n",
      "%autosave 15\n",
      "\n",
      "import os\n",
      "import sys\n",
      "\n",
      "import sklearn as sk\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier \n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import LinearSVC, SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "from sklearn.metrics import log_loss, accuracy_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      },
      {
       "javascript": [
        "IPython.notebook.set_autosave_interval(15000)"
       ],
       "metadata": {},
       "output_type": "display_data"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Autosaving every 15 seconds\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.base import BaseEstimator\n",
      "from sklearn.base import ClassifierMixin\n",
      "from sklearn.base import TransformerMixin\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "from sklearn.externals import six\n",
      "from sklearn.base import clone\n",
      "import numpy as np\n",
      "import operator\n",
      "\n",
      "\n",
      "class EnsembleClassifier(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
      "\n",
      "    def __init__(self, clfs, voting='hard', weights=None, fitted = False):\n",
      "        \n",
      "        self.clfs = clfs\n",
      "        self.voting = voting\n",
      "        self.weights = weights\n",
      "        self.fitted = fitted\n",
      "        \n",
      "    def fit(self, X, y):\n",
      "        \n",
      "        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n",
      "            raise NotImplementedError('Multilabel and multi-output'\\\n",
      "                                      ' classification is not supported.')\n",
      "\n",
      "        if self.voting not in ('soft', 'hard'):\n",
      "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n",
      "                             % voting)\n",
      "\n",
      "        if self.weights and len(self.weights) != len(self.clfs):\n",
      "            raise ValueError('Number of classifiers and weights must be equal'\n",
      "                             '; got %d weights, %d clfs'\n",
      "                             % (len(self.weights), len(self.clfs)))\n",
      "        \n",
      "\n",
      "        self.le_ = LabelEncoder()\n",
      "        self.le_.fit(y)\n",
      "        self.classes_ = self.le_.classes_\n",
      "        self.clfs_ = []\n",
      "        \n",
      "        if self.fitted == True:\n",
      "            for clf in self.clfs:\n",
      "                self.clfs_.append(clone(clf))\n",
      "            return self\n",
      "        \n",
      "        for clf in self.clfs:\n",
      "            fitted_clf = clone(clf).fit(X, self.le_.transform(y))\n",
      "            self.clfs_.append(fitted_clf)\n",
      "        return self\n",
      "\n",
      "    def predict(self, X):\n",
      "\n",
      "        if self.voting == 'soft':\n",
      "\n",
      "            maj = np.argmax(self.predict_proba(X), axis=1)\n",
      "\n",
      "        else:  # 'hard' voting\n",
      "            predictions = self._predict(X)\n",
      "\n",
      "            maj = np.apply_along_axis(\n",
      "                                      lambda x:\n",
      "                                      np.argmax(np.bincount(x,\n",
      "                                                weights=self.weights)),\n",
      "                                      axis=1,\n",
      "                                      arr=predictions)\n",
      "            \n",
      "        maj = self.le_.inverse_transform(maj)\n",
      "        return maj\n",
      "\n",
      "    def predict_proba(self, X):\n",
      "\n",
      "        avg = np.average(self._predict_probas(X), axis=0, weights=self.weights)\n",
      "        return avg\n",
      "\n",
      "    def transform(self, X):\n",
      "\n",
      "        if self.voting == 'soft':\n",
      "            return self._predict_probas(X)\n",
      "        else:\n",
      "            return self._predict(X)\n",
      "\n",
      "    def _predict(self, X):\n",
      "        if self.fitted == True:\n",
      "            return np.asarray([clf.predict(X) for clf in self.clfs]).T\n",
      "        return np.asarray([clf.predict(X) for clf in self.clfs_]).T\n",
      "\n",
      "    def _predict_probas(self, X):\n",
      "        if self.fitted == True:\n",
      "            return np.asarray([clf.predict_proba(X) for clf in self.clfs])\n",
      "        return np.asarray([clf.predict_proba(X) for clf in self.clfs_])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load data\n",
      "\n",
      "ROOT = r'D:\\Projects\\Kaggle\\OttoGroup'\n",
      "DATA = ROOT + \"/data\"\n",
      "\n",
      "data_train = pd.read_csv(DATA + \"\\\\\" + \"train.csv\")\n",
      "data_train = data_train.drop('id', axis=1)\n",
      "\n",
      "data_test = pd.read_csv(DATA + \"\\\\\" + \"test.csv\")\n",
      "data_test_id = data_test['id']\n",
      "data_test = data_test.drop('id', axis=1)\n",
      "\n",
      "data_train.target = data_train.target.apply(lambda x: int(x.split(\"_\")[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train & test\n",
      "train_target = data_train.target\n",
      "train = data_train.drop('target', axis=1)\n",
      "\n",
      "X_train, X_test, y_train, y_test = sk.cross_validation.train_test_split(train, train_target, test_size=0.2, random_state=23)\n",
      "print(X_train.shape, y_train.shape)\n",
      "print(X_test.shape, y_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "((49502L, 93L), (49502L,))\n",
        "((12376L, 93L), (12376L,))\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_reg = LogisticRegression()\n",
      "log_reg.fit(X_train, y_train)\n",
      "print(log_reg.score(X_train, y_train))\n",
      "print(log_reg.score(X_test, y_test))\n",
      "\n",
      "rf = RandomForestClassifier()\n",
      "rf.fit(X_train, y_train)\n",
      "print(rf.score(X_train, y_train))\n",
      "print(rf.score(X_test, y_test))\n",
      "\n",
      "gbm = GradientBoostingClassifier(n_estimators=10)\n",
      "gbm.fit(X_train, y_train)\n",
      "print(gbm.score(X_train, y_train))\n",
      "print(gbm.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.759201648418\n",
        "0.752747252747\n",
        "0.992808371379"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.776906916613"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.71989010545"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.712427278604\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf1 = LogisticRegression()\n",
      "clf2 = RandomForestClassifier()\n",
      "clf3 = GradientBoostingClassifier(n_estimators=10)\n",
      "essemble_classifier = EnsembleClassifier(clfs=[clf1, clf2, clf3], voting='soft')\n",
      "essemble_classifier.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "EnsembleClassifier(clfs=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001), RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "        ...   min_samples_split=2, n_estimators=10, random_state=None,\n",
        "              subsample=1.0, verbose=0)],\n",
        "          fitted=False, voting='soft', weights=None)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(essemble_classifier.score(X_train, y_train))\n",
      "print(essemble_classifier.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.918568946709\n",
        "0.782401422107"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pipeline\n",
      "http://scikit-learn.org/stable/auto_examples/feature_stacker.html\n",
      "http://scikit-learn.org/stable/auto_examples/plot_digits_pipe.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}